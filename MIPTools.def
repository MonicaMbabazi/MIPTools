Bootstrap: docker
From: amd64/ubuntu:18.04

%post
    # set number of cpus to use in build
    CPU_COUNT=20
    # set build environment
    export DEBIAN_FRONTEND=noninteractive \
        CONDA_DIR=/opt/conda \
        SHELL=/bin/bash \
        LANG=en_US.UTF-8 \
        LANGUAGE=en_US.UTF-8 \
        LC_ALL=en_US.UTF-8 \
        MINICONDA_VERSION=4.7.12.1
    export PATH=$CONDA_DIR/bin:$PATH

    # install system packages
    apt-get update \
    && apt-get -yq dist-upgrade \
    && apt-get install -yq --no-install-recommends \
    wget \
    bzip2 \
    ca-certificates \
    sudo \
    locales \
    fonts-liberation \
    fonts-dejavu \
    git \
    build-essential \
    gcc \
    openssh-client \
    nano \
    libtbb-dev \
    libz-dev \
    libxrender1 \
    cmake \
    automake \
    autoconf \
    rsync \
    pigz \
    perl-tk \
    less \
    software-properties-common \
    libxext6 \
    libxrender1 \
    ghostscript \
    openjdk-11-jdk \
    liblzma-dev \
    libbz2-dev \
    libssl-dev \
    libcurl4-gnutls-dev \
    alien \
    unzip \
    tree

    # set environment locale
    echo "en_US.UTF-8 UTF-8" >> /etc/locale.gen
    echo "LANG=en_US.UTF-8" > /etc/locale.conf
    echo "LC_ALL=en_US.UTF-8" >> /etc/environment
    echo "LANGUAGE=en_US.UTF-8" >> /etc/environment
    locale-gen en_US.UTF-8
    update-locale LANG=en_US.UTF-8

    # install bcl2fastq, if the file is there
    cd /opt/programs
    unzip bcl2fastq2*.zip || true
    alien bcl2fastq2*.rpm || true
    dpkg -i bcl2fastq2*.deb || true

    # install msa2vcf
    cd /opt/programs
    git clone https://github.com/lindenb/jvarkit.git
    cd jvarkit
    ./gradlew msa2vcf

    # install conda
    cd /tmp && \
        wget --quiet https://repo.continuum.io/miniconda/Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh && \
        echo "81c773ff87af5cfac79ab862942ab6b3 *Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh" | md5sum -c - && \
        /bin/bash Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh -f -b -p $CONDA_DIR && \
        rm Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh && \
        $CONDA_DIR/bin/conda config --system --append channels r && \
        $CONDA_DIR/bin/conda config --system --append channels bioconda && \
        $CONDA_DIR/bin/conda config --system --append channels conda-forge && \
        $CONDA_DIR/bin/conda config --system --set auto_update_conda true && \
        $CONDA_DIR/bin/conda config --system --set show_channel_urls true && \
        $CONDA_DIR/bin/conda install --quiet --yes conda="${MINICONDA_VERSION%.*}.*" && \
        $CONDA_DIR/bin/conda update --all --quiet --yes && \
        conda clean -tipsy

    # install conda packages
    conda config --add channels bioconda
    conda config --add channels r
    conda install -qy \
    "r-epitools=0.5_10" \
    "r=3.6.0" \
    "rpy2=2.9.4" \
    "python=3.6.8" \
    "notebook=6.0.3" \
    "xlrd=1.2.0" \
    "bcftools=1.10" \
    "samtools=1.10" \
    "htslib=1.10" \
    "bwa=0.7.17" \
    "bowtie2=2.3.5" \
    "primer3=2.5.0" \
    "primer3-py=0.6.0" \
    "numpy=1.17.5" \
    "scipy=1.4.1" \
    "biopython=1.76" \
    "pysam=0.15" \
    "pandas=0.25" \
    "matplotlib=3.1" \
    "seaborn=0.9" \
    "scikit-learn=0.22.1" \
    "scandir=1.10.0" \
    "openpyxl=3.0.3" \
    "simplegeneric=0.8.1" \
    "matplotlib-venn=0.11.5" \
    "tblib=1.6.0" \
    "parallel=20191122" \
    "scikit-allel=1.2.1" \
    "bioconductor-dnacopy=1.60" \
    "basemap-data-hires=1.2.1" \
    "seqtk=1.3"


    conda clean -tipsy

    # install vt variant tool set
    cd /opt/programs
    git clone https://github.com/atks/vt.git
    cd vt
    make -j $CPU_COUNT
    scp vt /opt/bin


    # install lastZ
    cd /opt/programs/lastz/src
    make lastz_32 && install lastz_32 /usr/bin/

    # install freebayes
    cd /opt/bin
    freebayes_ver="v1.3.1"
    freebayes_file=freebayes-$freebayes_ver
    wget https://github.com/ekg/freebayes/releases/download/$freebayes_ver/$freebayes_file
    mv $freebayes_file freebayes

    # install MIPWrangler
    cd /opt/programs
    git clone https://github.com/bailey-lab/MIPWrangler
    cd MIPWrangler
    git checkout develop
    ./upgradeDevelop.sh $CPU_COUNT

    # install elucidator
    cd /opt/programs
    git clone https://github.com/nickjhathaway/elucidator
    cd elucidator
    git checkout develop
    ./install.sh $CPU_COUNT

    # install gatk
    gatk_ver="4.1.4.1"
    gatk_dir=/opt/programs/gatk-$gatk_ver
    gatk_filename=gatk-$gatk_ver".zip"
    cd /opt/programs
    wget https://github.com/broadinstitute/gatk/releases/download/$gatk_ver/$gatk_filename
    unzip $gatk_filename
    rm $gatk_filename
    mv gatk-$gatk_ver gatk

    # install parasight
    scp /opt/programs/parasight_v7.6/parasight.pl /opt/bin/parasight76.pl

    # add executable flag to executables
    chmod -R +xr /usr/bin
    chmod -R +xr /opt/bin


    # create work and resources directories in /opt
    mkdir /opt/resources \
        /opt/work \
        /opt/project_resources \
        /opt/species_resources \
        /opt/data \
        /opt/analysis \
        /opt/host_species \
        /opt/extras


%files
    programs /opt
    bin /opt
    src /opt

%environment
    path=/opt/bin:/opt/conda/bin:/opt/programs/MIPWrangler/bin:
    path=$path/opt/programs/elucidator/bin:/opt/programs/gatk:
    path=$path$PATH
    export PATH=$path
    export XDG_RUNTIME_DIR=""
    export DEBIAN_FRONTEND=noninteractive
    export LANG=en_US.UTF-8
    export LANGUAduGE="en_US.UTF-8"
    export LC_ALL="en_US.UTF-8"

%apprun jupyter
    set -e
    set -u
    nb_port=$(shuf -i 8000-9999 -n 1)
    server_ip=$(hostname -i)
    server_user=$(whoami)@$(hostname -f)
    nb_dir=/opt
    while getopts p:d: OPT; do
        case "$OPT" in
            p)
              nb_port="$OPTARG";;
            d)
              nb_dir="$OPTARG";;
            *)
              echo "Invalid option. Use -p to specify notebook port \
                   -d to specify notebook directory."
        esac
    done
    rsync /opt/resources/*.ipynb /opt/analysis --ignore-existing \
        --ignore-missing-args
    port_fw="Use the following command if you are running this notebook from "
    port_fw=$port_fw"a remote server. Ignore if using a local computer."
    echo $port_fw
    port_fw="ssh -N -f -L localhost:$nb_port:$server_ip:$nb_port $server_user"
    echo $port_fw
    jupyter notebook --notebook-dir=$nb_dir --ip=$server_ip \
            --port=$nb_port --no-browser

%apprun wrangler
    set -e
    set -u
    # set defaults
    cluster_script="runMIPWranglerCurrent.sh"
    server_number=1
    cpu_count=1
    min_capture_length="none"
    stitch_options="none"
    keep_files=""
    while getopts p:l:e:s:w:n:c:x:m:k OPT; do
        case "$OPT" in
            e)
              experiment_id="$OPTARG";;
            l)
              sample_list="$OPTARG";;
            p)
              probe_sets="$OPTARG";;
            s)
              sample_sets="$OPTARG";;
            w)
              cluster_script="$OPTARG";;
            n)
              server_number="$OPTARG";;
            c)
              cpu_count="$OPTARG";;
            x)
              stitch_options="$OPTARG";;
            k)
              keep_files="-k";;

            m)
              min_capture_length="$OPTARG";;

            *)
              echo "Invalid option. Use 'wrangler \
              -e experiment_id -l sample_list.file -p  probe_sets\
              -s sample_sets -w cluster_script -n server_number \
              -c  cpu_count -x additional_stitch_options'  \
              -m min_capture_length [-k]"
        esac
    done
    python /opt/src/generate_wrangler_scripts.py \
    -e $experiment_id -l /opt/analysis/$sample_list \
    -p $probe_sets -s $sample_sets -w $cluster_script -n $server_number \
    -c $cpu_count -x $stitch_options -m $min_capture_length $keep_files
    script_name=$sample_sets"_"$(echo $probe_sets|tr "," "_")".sh"
    . /opt/analysis/$script_name

%apprun download
    set -e
    set -u
    while getopts r: opt; do
        case $opt in
            r)  run_id=$OPTARG;;
            ?)  echo "Usage: singularity run --app download \\"
                echo "           -B /path_to_output_dir:/opt/analysis \\"
                echo "           -B /path_to_base_resources:/opt/resources \\"
                echo "            mycontainer.sif -r my_Illumina_run_ID"
                echo "An 'access_token.txt' file with a valid access token is "
                echo "required. It must be present in base_resources directory."
                echo "A data directory where the data will be downloaded to"
                echo "must be mounted to /opt/data."
                exit 1;;
        esac
    done
    echo "Downloading NextSeq run $run_id from BaseSpace."
    echo "Depending on the data size, this can take very long (up to 10 h)"
    echo "It is recommended to run this app in a screen (GNU screen)."
    echo "A message indicating the end of download will be printed when done."
    echo "Check nohup.out file in your output directory for the download log."
    cd /opt/analysis
    nohup python /opt/bin/BaseSpaceRunDownloader_v2.py \
     -r $run_id -a "$(cat /opt/resources/access_token.txt)"
    echo "Download finished."

%apprun demux
    set -e
    set -u
    while getopts s:p: opt; do
        case $opt in
            s)  sample_list=$OPTARG;;
            p)  platform=$OPTARG;;
            ?)  echo "Usage: singularity run --app demux \\"
                echo "           -B /path_to_run_dir:/opt/data \\"
                echo "           -B /path_to_output_dir:/opt/analysis \\"
                echo "           -B /path_to_base_resources:/opt/resources \\"
                echo "            mycontainer.sif -s sample_list_file \\"
                echo "            -p sequencing_platform (nextseq or miseq) \\"
                echo "The sample list file must be present in the output"
                echo "directory mounted to /opt/analysis."
                exit 1;;
        esac
    done
    # create a sample sheet for demultiplexing
    cd /opt/src
    template_dir="/opt/resources/templates/sample_sheet_templates/"
    platform_template="$platform"_sample_sheet_template.csv
    template="$template_dir$platform_template"
    bc_dict="/opt/resources/barcode_dict.json"
    output_dir="/opt/analysis"
    sample_list="/opt/analysis/$sample_list"
    python -c 'import mip_functions as mip; mip.generate_sample_sheet(
        "'"$sample_list"'", "'"$bc_dict"'", "'"$template"'", "'"$platform"'",
        "'"$output_dir"'")'
    # cd to where bcl files are.
    cd /opt/data
    # create a fastq directory for saving fastqs
    mkdir -p /opt/analysis/fastq
    # increase limit of open number of files.
    ulimit -Sn $(ulimit -Hn)
    nohup bcl2fastq -o /opt/analysis/fastq \
        --sample-sheet /opt/analysis/SampleSheet.csv \
        --no-lane-splitting

%apprun demux_qc
    set -e
    set -u
    while getopts p: opt; do
        case $opt in
            p)  platform=$OPTARG;;
            ?)  echo "Usage: singularity run --app demux_qc\\"
                echo "           -B /path_to_base_resources:/opt/resources \\"
                echo "           -B /path_to_fastq_dir:/opt/analysis "
                echo "            mycontainer.sif -p sequencing_platform"
                exit 1;;
        esac
    done
    python /opt/src/demux_qc.py -p $platform
