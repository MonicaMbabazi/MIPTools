--- mip_functions_testing.py	(original)
+++ mip_functions_testing.py	(refactored)
@@ -24,7 +24,7 @@
 import random
 import string
 from ast import literal_eval as evaluate
-import cPickle as pickle
+import pickle as pickle
 import copy
 from Bio import SeqIO
 import numpy as np
@@ -39,7 +39,7 @@
 import mip_mod_testing as mod
 import pandas as pd
 import gzip
-print "functions reloading"
+print("functions reloading")
 
 
 # > Below class allows processors from a pool from multiprocessing module to create processor pools of their own.
@@ -76,7 +76,7 @@
         for line in infile:
             if not line.startswith("#"):
                 newline = line.strip().split("\t")
-                if newline[0] not in file_locations.keys():
+                if newline[0] not in list(file_locations.keys()):
                     file_locations[newline[0]] = {newline[1]:newline[2]}
                 else:
                     file_locations[newline[0]][newline[1]] = newline[2]
@@ -190,7 +190,7 @@
             if line.startswith("BASE"):
                 newline = line.strip().split('\t')
                 if newline[1] != "0":
-                    print "File is not zero offset, exiting."
+                    print("File is not zero offset, exiting.")
                     return
         with open(output_file, "w") as outfile:
             for line in infile:
@@ -262,7 +262,7 @@
                             "min_mips", "max_mips",  "mask_diffs_lig",
                             "mask_diffs_ext", "mask_snps_lig", "mask_snps_ext"]
             outfile.write("\t".join(capture_list) + "\n")
-            segment_list = segment_dic.keys()
+            segment_list = list(segment_dic.keys())
             segment_list.sort()
             for seg in segment_list:
                 if len(segment_dic[seg])> 1:
@@ -499,10 +499,10 @@
         for reg in regions:
             region_name = "-".join(reg[2])
             region_targets = reg[3][0]
-            for i in xrange(len(region_targets)):
+            for i in range(len(region_targets)):
                 reg_name = region_name + "-" + str(i)
                 if reg_name in target_coordinates:
-                    print reg_name, " is already in targets!"
+                    print(reg_name, " is already in targets!")
                 else:
                     target_coordinates[reg_name] = region_targets[i]
     """
@@ -565,12 +565,12 @@
         if len(snp_locations[s]) == 1:
             reference_snp_locations[s] = snp_locations[s][0]
         else:
-            for i in xrange(len(snp_locations[s])):
+            for i in range(len(snp_locations[s])):
                 if len(snp_locations[s][i]["chrom"].split("_")) == 1:
                     reference_snp_locations[s] = snp_locations[s][i]
                     break
             else:
-                print "Short chromosome name not found! Please check the output list."
+                print("Short chromosome name not found! Please check the output list.")
                 problem_snps.append(s)
         reference_snp_locations[s]["capture_type"] = capture_types[s]
     return reference_snp_locations, snp_locations
@@ -601,7 +601,7 @@
 
 def gene_to_target_exons(gene_list, species, exon_list):
     target_coordinates = {}
-    for i in xrange(len(gene_list)):
+    for i in range(len(gene_list)):
         gene = gene_list[i]
         exons_wanted = exon_list[i]
         gene_exons = get_exons(get_gene(gene,
@@ -611,7 +611,7 @@
         if gene_exons["orientation"] == "-":
             exons.reverse()
         if exons_wanted == "all":
-            for j in xrange(len(exons)):
+            for j in range(len(exons)):
                 e = exons[j]
                 tar_name = "-".join([gene, "exon", str(j)])
                 target_coordinates[tar_name] = {"chrom":gene_exons["chrom"],
@@ -626,7 +626,7 @@
                                                     "begin": e[0],
                                                     "end": e[1]}
                 except IndexError:
-                    print "Exon ", j, " does not exist for gene ", gene
+                    print("Exon ", j, " does not exist for gene ", gene)
     return target_coordinates
 
 
@@ -690,7 +690,7 @@
                get_file_locations()["hs"]["hg19.config"]]
     try:
         res = subprocess.check_output(command, cwd = gene_name + "/resources")
-    except subprocess.CalledProcessError, e:
+    except subprocess.CalledProcessError as e:
         return e.output
     return
 def paralog_rinfo_maker(family_name, gene_dic):
@@ -849,7 +849,7 @@
         # run the command using subprocess module
         subprocess.check_output(comm)
         return 0
-    except Exception, e:
+    except Exception as e:
         return str(e)
 def align_region_multi_for_design(alignment_list, pro):
     res = []
@@ -858,7 +858,7 @@
         p.map_async(align_region_worker_for_design, alignment_list, callback=res.append)
         p.close()
         p.join()
-    except Exception, e:
+    except Exception as e:
         res.append(str(e))
     return res
     
@@ -944,7 +944,7 @@
         # run the command using subprocess module
         subprocess.check_output(comm)
         return 0
-    except Exception, e:
+    except Exception as e:
         return str(e)
 def align_region_multi(alignment_list, pro):
     res = []
@@ -953,7 +953,7 @@
         p.map_async(align_region_worker, alignment_list, callback=res.append)
         p.close()
         p.join()
-    except Exception, e:
+    except Exception as e:
         res.append(str(e))
     return res
 
@@ -1004,7 +1004,7 @@
         comm.extend(options)
         subprocess.check_output(comm)
         return 0
-    except Exception, e:
+    except Exception as e:
         return str(e)
 
 
@@ -1399,7 +1399,7 @@
                     # keep track of the index of haplotype sequence
                     # to use for checking sequence quality later
                     hap_index = 0
-                    for i in xrange(len(diff)):
+                    for i in range(len(diff)):
                         d = diff[i]
                         # each difference between the hap and ref can be an indel ("-")
                         # or a snp (":" or "x") or the same as the reference (".")
@@ -1430,7 +1430,7 @@
                             else:
                                 # if neither hap nor ref has "-" at this position there is
                                 # a disagreement between the alignment and the sequences
-                                print "Alignment shows indel but sequences do not", h_name
+                                print("Alignment shows indel but sequences do not", h_name)
                                 break
                         else:
                             # if the current diff is not an indel,
@@ -1685,7 +1685,7 @@
                 best_al = copy_als[0]
             else:
                 best_al_score = 0
-                for i in xrange(len(copy_als)):
+                for i in range(len(copy_als)):
                     sc = copy_als[i]["score"] 
                     if sc > best_al_score:
                         best_al_score = sc
@@ -1698,9 +1698,9 @@
     # check if problem alignments and inverted alignments have a better alignment in 
     # alignment dictionary. Remove from list if better is found elsewhere.
     problem_dicts = [problem_alignments, inverted_alignments]
-    for i in xrange(len(problem_dicts)):
+    for i in range(len(problem_dicts)):
         probs = problem_dicts[i]
-        for j in xrange(len(probs)):
+        for j in range(len(probs)):
             a = probs[j]
             hap_name = a["haplotype_ID"]
             al_score = a["score"]
@@ -1724,9 +1724,9 @@
                     temp_dict[hap_name] = [a]
         problem_dicts[i] = temp_dict
         if len(temp_dict) > 0:
-            print "Some alignments may have problems, please check %s"            %settings["tempAlignmentsFile"]
+            print("Some alignments may have problems, please check %s"            %settings["tempAlignmentsFile"])
     if len(problem_snps) > 0:
-        print "Some SNPs may have problems, please check please check %s"            %settings["tempAlignmentsFile"]
+        print("Some SNPs may have problems, please check please check %s"            %settings["tempAlignmentsFile"])
     
     result =  {"alignments": alignments,
             "inverted_alignments": problem_dicts[1],
@@ -1846,7 +1846,7 @@
             copy_keys_sorted = sorted(copy_sort, key = itemgetter(f, s))
             copy_keys_sorted_temp = copy.deepcopy(copy_keys_sorted)
             # remove alt contigs 
-            for cop_ind in xrange(len(copy_keys_sorted)):
+            for cop_ind in range(len(copy_keys_sorted)):
                 cop = copy_keys_sorted[cop_ind]
                 if "alt" in call_info[gene_name][m]["copies"][cop[0]]["chrom"]:
                     copy_keys_sorted[cop_ind] = "remove"
@@ -2063,12 +2063,12 @@
             else:
                 normalized_key = normalized_variation_keys[line_num]
                 if not normalized_key in variation:
-                    variation[normalized_key] = {colnames[i] : newline[i]                                                  for i in xrange(len(colnames))}
+                    variation[normalized_key] = {colnames[i] : newline[i]                                                  for i in range(len(colnames))}
                 line_num += 1
     #print temp_variation_keys[:10]
     #print var_key_to_uniq.keys()[:10]
     if line_num != len(temp_variation_keys):
-        print "There are more variation keys then annotated variants."
+        print("There are more variation keys then annotated variants.")
     
     for m in haplotypes:
         for h in haplotypes[m]:
@@ -2123,8 +2123,8 @@
     except IOError:
         raw_data = []
     mipster_file = wdir + settings["mipsterFile"] 
-    colnames = dict(zip(settings["colNames"],
-                        settings["givenNames"]))
+    colnames = dict(list(zip(settings["colNames"],
+                        settings["givenNames"])))
     with open(mipster_file) as infile:
         ## filteredData only contains relevant fields for this analysis
         # the field names are given in the settings dict and
@@ -2137,7 +2137,7 @@
                 line_number += 1
                 col_indexes = {}
                 try:
-                    for ck in colnames.keys():
+                    for ck in list(colnames.keys()):
                         col_indexes[
                             newline.index(ck)
                         ] = {"name": colnames[ck]}
@@ -2146,7 +2146,7 @@
                         elif ck == 'c_readCnt':
                             rc_index = newline.index(ck)
                 except ValueError:
-                    for ck in colnames.values():
+                    for ck in list(colnames.values()):
                         col_indexes[
                         newline.index(ck)
                         ] = {"name" : ck}
@@ -2156,7 +2156,7 @@
                             rc_index = newline.index(ck)
                 # each data point will be a dict
                 data_dic = {}
-                for i in col_indexes.keys():
+                for i in list(col_indexes.keys()):
                     # check data type and convert data appropriately
                     if i in [bc_index, rc_index]:
                         data_point = int(newline[i])
@@ -2290,7 +2290,7 @@
             #all_mipnames.append(mip_name)
     
     
-    for s in samples.keys():
+    for s in list(samples.keys()):
         try:
             samples[s]["diploid_mip_names"] = list(set((samples[s]["diploid_mip_names"])))
             samples[s]["diploid_mip_number"] = len(samples[s]["diploid_mip_names"])
@@ -2404,11 +2404,11 @@
                             "haplotypes": []}
                     temp_data_points = copy.deepcopy(data_points)
                     # group data points with same haplotype_ID together
-                    for i in xrange(len(temp_data_points)):
+                    for i in range(len(temp_data_points)):
                         di = temp_data_points[i]
                         if di != "remove":
                             same_haps = [di]
-                            for j in xrange(len(temp_data_points)):
+                            for j in range(len(temp_data_points)):
                                 if i != j:
                                     dj = temp_data_points[j]
                                     if dj != "remove" and (di["haplotype_ID"] ==                                                            dj["haplotype_ID"]):
@@ -2419,14 +2419,14 @@
                         # find data point with most barcodes
                         temp_barcode_count = 0
                         best_data_index = 0
-                        for i in xrange(len(dl)):
+                        for i in range(len(dl)):
                             b = dl[i]["barcode_count"]
                             if b > temp_barcode_count:
                                 temp_barcode_count = b
                                 best_data_index = i
                         # use data point with more barcodes as base
                         dm = copy.deepcopy(dl[best_data_index])
-                        for i in xrange(len(dl)):
+                        for i in range(len(dl)):
                             if i != best_data_index:
                                 dt = dl[i]
                                 for k in merge_keys:
@@ -2536,7 +2536,7 @@
     no_copy_keys = {}
     for g in all_copy_names:
         copies = all_copy_names[g]
-        keys = sorted(call_info[g].keys(), 
+        keys = sorted(list(call_info[g].keys()), 
                       key= lambda a: call_info[g][a]["copies"]["C0"]["capture_start"])
         for k in keys:
             try:
@@ -2548,19 +2548,19 @@
                         split_copies = c.split("_")
                         nucopies.append([split_copies[i+1]                                              for i in range(0, len(split_copies), 2)])
                 except IndexError:
-                    print split_copies
+                    print(split_copies)
                     break
-                for i in xrange(len(nucopies)):
+                for i in range(len(nucopies)):
                     query_list = nucopies[i]
-                    for j in xrange(len(nucopies)):
+                    for j in range(len(nucopies)):
                         target_list = nucopies[j]
                         if i != j:
                             for c in query_list:
                                 if c in target_list:
                                     toss_copies.append(i)
                 toss_copies = list(set(toss_copies))
-                uniq_copies = [key_copies[i]                                for i in xrange(len(key_copies)) if i not in toss_copies]
-                non_uniq_copies = [key_copies[i]                                for i in xrange(len(key_copies)) if i in toss_copies]
+                uniq_copies = [key_copies[i]                                for i in range(len(key_copies)) if i not in toss_copies]
+                non_uniq_copies = [key_copies[i]                                for i in range(len(key_copies)) if i in toss_copies]
                 if len(uniq_copies) > 0:
                     try:
                         uniq_keys[g][k] = uniq_copies
@@ -2603,7 +2603,7 @@
     sample_results_file = wdir + settings["perSampleResults"]
     with open(sample_results_file) as infile:
         counts = json.load(infile)
-    sample_names = counts.keys()
+    sample_names = list(counts.keys())
     big_table = []
     all_tables = {}
     for gene in call_info:
@@ -2629,7 +2629,7 @@
                     gc_frac = calculate_gc(probe_info["capture_sequence"])
                 elif len(split_copies) > 2:
                     gc_list = []
-                    for i in xrange(0, len(split_copies), 2):
+                    for i in range(0, len(split_copies), 2):
                         c_id = split_copies[i+1]
                         probe_info = gene_info[p]["copies"][c_id]
                         gc_list.append(calculate_gc(probe_info["capture_sequence"]))
@@ -2753,9 +2753,9 @@
             copy_counts = tables[g]["median_normalized_copy_counts"]
             barcode_counts = np.transpose(tables[g]["sample_normalized_barcode_counts"])
             collapsed_counts = np.zeros((len(uniq_probes), len(sample_names)))
-            for i in xrange(len(uniq_probes)):
+            for i in range(len(uniq_probes)):
                 u = uniq_probes[i]
-                for j in xrange(len(probes)):
+                for j in range(len(probes)):
                     p = probes[j]
                     if u == p:
                         collapsed_counts[i] += copy_counts[j]
@@ -2794,7 +2794,7 @@
                                     "V": V,
                                     "Y": Y},
                            "clusters": {}}
-            for k in xrange(n_clusters_):
+            for k in range(n_clusters_):
                 my_members = cluster_labels == k
                 cluster_center = cluster_centers[k]
                 cluster_case_count = list(np.asarray(labels)[my_members]).count("case")
@@ -2824,7 +2824,7 @@
                            "collapsed_medians": np.median(collapsed_counts[my_members], axis=0)
                            }
             cluster_output[g] = cluster_dict
-        except Exception, e:
+        except Exception as e:
             problem_clusters.append([g, e])
     cluster_output_file = wdir + settings["clusterOutputFile"]
     with open(cluster_output_file, "w") as outfile:
@@ -2878,9 +2878,9 @@
                     labels.append("na")
             copy_counts = tables[g]["median_normalized_copy_counts"]
             collapsed_counts = np.zeros((len(uniq_probes), len(sample_names)))
-            for i in xrange(len(uniq_probes)):
+            for i in range(len(uniq_probes)):
                 u = uniq_probes[i]
-                for j in xrange(len(probes)):
+                for j in range(len(probes)):
                     p = probes[j]
                     if u == p:
                         collapsed_counts[i] += copy_counts[j]
@@ -2904,7 +2904,7 @@
                 cluster_count.append([n_clusters_, unclustered])
             # find the best clustering
             indexes_PF = []
-            for i in xrange(len(cluster_count)):
+            for i in range(len(cluster_count)):
                 cc = cluster_count[i][0]
                 un = cluster_count[i][1]
                 if cc <= max_cluster_count and un <= max_unclustered_frac :
@@ -2939,7 +2939,7 @@
                            "dbscan": db,
                            "tsne": cnv_calls[g]["tsne"],
                            "clusters": {}}
-            for k in xrange(n_clusters_):
+            for k in range(n_clusters_):
                 my_members = cluster_labels == k
                 #cluster_center = cluster_centers[k]
                 cluster_case_count = list(np.asarray(labels)[my_members]).count("case")
@@ -2969,7 +2969,7 @@
                            "collapsed_medians": np.median(collapsed_counts[my_members], axis=0)
                            }
                 cluster_output[g] = cluster_dict
-        except Exception, e:
+        except Exception as e:
             problem_clusters.append([g, e])
     db_output_file = wdir + settings["dbScanOutputFile"]
     with open(db_output_file, "w") as outfile:
@@ -3007,19 +3007,19 @@
         probe_table = tables["probe_information"]
         copies = [probe_table[0,2]]
         locations = [0]
-        for i in xrange(len(probe_table) -1):
+        for i in range(len(probe_table) -1):
             current_copy = probe_table[i+1, 2]
             if current_copy != copies[-1]:
                 copies.append(current_copy)
                 locations.extend([i, i+1])
         locations.append(len(probe_table))
-        locations = [[locations[i], locations[i+1]] for i in xrange(0, len(locations), 2)]
+        locations = [[locations[i], locations[i+1]] for i in range(0, len(locations), 2)]
         upper_limit = cnv_calls[gene_name]["plotting"]["upper_limit"]
         lower_limit = cnv_calls[gene_name]["plotting"]["lower_limit"]
         fig1 = plt.figure(figsize=figsize)
         fig2 = plt.figure(figsize=figsize)
         fig3 = plt.figure(figsize=figsize)
-        for c in xrange(len(clusters)):
+        for c in range(len(clusters)):
             ax1 = fig1.add_subplot(len(clusters), 1, c)
             ax2 = fig2.add_subplot(len(clusters), 1, c)
             ax3 = fig3.add_subplot(len(clusters), 1, c)
@@ -3048,7 +3048,7 @@
             ax3.plot(upper_limit, lw = 2, c = "g")
             ax3.plot(lower_limit, lw = 2, c = "r")
             colors = ["y", "k"]
-            for i in xrange(len(copies)):
+            for i in range(len(copies)):
                 copyname = copies[i]
                 loc = locations[i]
                 ax1.plot(np.arange(loc[0]-1, loc[1]+1), np.zeros(loc[1]- loc[0]+2),
@@ -3225,7 +3225,7 @@
                                                     try:
                                                         snp_results[g][s][m][c][sam] =                                                         [[nbc, rbc, msnps[s]["copies"][copy_id]["copy_base"],
                                                         msnps[s]["copies"][copy_id]["copy_base"], 0]]
-                                                    except KeyError, e:
+                                                    except KeyError as e:
                                                         temp.append([g,s,m,c,sam, copy_id, e])
             
     for g in snp_results:
@@ -3263,7 +3263,7 @@
                             
                             
                         else:
-                            i = map(list, zip(*l))
+                            i = list(map(list, list(zip(*l))))
                             genotype = "/".join(i[3])
                             bc_count = i[1]
                             hom_set = sorted(list(set(i[-1])))
@@ -3442,7 +3442,7 @@
                 colnames.extend(newline[1:])
             else:
                 temp_dict = {}
-                for i in xrange(len(colnames)):
+                for i in range(len(colnames)):
                     col = colnames[i]
                     value = newline[i]
                     temp_dict[col] = value
@@ -3476,7 +3476,7 @@
     overlap_found = True
     while overlap_found:
         overlap_found = False
-        for o in overlaps.keys():
+        for o in list(overlaps.keys()):
             if o in overlaps:
                 val = overlaps[o]
                 for v in val:
@@ -3549,7 +3549,7 @@
             outfile.write(get_sequence(query_key, species))
         with open(resource_dir + t + ".targets.fa", "w") as outfile:
             outfile_list = []
-            for i in xrange(len(target_keys)):
+            for i in range(len(target_keys)):
                 k = target_keys[i]
                 cname = "_C" + str(i)
                 outfile_list.append(">" + t + cname)
@@ -3689,7 +3689,7 @@
     for ci in sorted(new_regions):
         ret_regions.extend(sorted(new_regions[ci]))
         if len(new_regions[ci]) > 1:
-            for i in xrange(len(new_regions[ci])):
+            for i in range(len(new_regions[ci])):
                 rnames.append(
                     region_names[ci] + "-" + str(i)
                 )
@@ -3907,14 +3907,14 @@
             rev_co = alignment_dic[aname]["reverse_coordinates"]
             if qname not in return_dic:
                 return_dic[qname] = alignment_dic[aname]
-                return_dic[qname]["covered"] = [map(int, [alignment_dic[aname]["zstart1"],
-                                                 alignment_dic[aname]["end1"]])]
+                return_dic[qname]["covered"] = [list(map(int, [alignment_dic[aname]["zstart1"],
+                                                 alignment_dic[aname]["end1"]]))]
             else:
                 qname_cov = [alignment_dic[aname]["zstart1"],
                             alignment_dic[aname]["end1"]]
-                return_dic[qname]["covered"].append(map(int, qname_cov))
+                return_dic[qname]["covered"].append(list(map(int, qname_cov)))
         return alignment_dic, return_dic
-    except Exception, e:
+    except Exception as e:
         return [family_name, e]
 
 
@@ -4107,7 +4107,7 @@
         # number of alleles for each genotype in the form (m,n,..)
         if snp[col] != "":
             acs = [a for a in snp[col].split(",") if a != ""]
-            allele_count = map(int, map(float, acs))
+            allele_count = list(map(int, list(map(float, acs))))
             # allele with max count
             max_all = max(allele_count)
             # total alleles
@@ -4117,8 +4117,8 @@
             if (maf >= min_allele_freq) and (tot_all >= min_total_allele):
                 # snp satisfying the given criteria is filtered
                 filtered_snps.append(snp)
-    print " ".join(["Found", str(len(filtered_snps)), "SNPs with >=", str(min_allele_freq),
-                    "frequency and >=", str(min_total_allele), "reported alleles!"])
+    print(" ".join(["Found", str(len(filtered_snps)), "SNPs with >=", str(min_allele_freq),
+                    "frequency and >=", str(min_total_allele), "reported alleles!"]))
     return filtered_snps
 
 
@@ -4139,7 +4139,7 @@
             allele_count_list = snp[col].split(",")
             if allele_count_list[-1] == "":
                 allele_count_list.pop(-1)
-            allele_count = map(int, map(float, allele_count_list))
+            allele_count = list(map(int, list(map(float, allele_count_list))))
             # allele with max count
             max_all = max(allele_count)
             # total alleles
@@ -4149,8 +4149,8 @@
             if (maf >= min_allele_freq) and (tot_all >= min_total_allele):
                 # snp satisfying the given criteria is filtered
                 filtered_snps.append(snp)
-    print " ".join(["Found", str(len(filtered_snps)), "SNPs with >=", str(min_allele_freq),
-                    "frequency and >=", str(min_total_allele), "reported alleles!"])
+    print(" ".join(["Found", str(len(filtered_snps)), "SNPs with >=", str(min_allele_freq),
+                    "frequency and >=", str(min_total_allele), "reported alleles!"]))
     return filtered_snps
 
 
@@ -4169,7 +4169,7 @@
         submitter_list = snp[20].strip().split(',')[:-1]
         # number of alleles for each genotype in the form (m,n,..)
         if snp[col] != "":
-            allele_count = map(int, map(float, snp[col].split(",")[:-1]))
+            allele_count = list(map(int, list(map(float, snp[col].split(",")[:-1]))))
             # allele with max count
             max_all = max(allele_count)
             # total alleles
@@ -4184,8 +4184,8 @@
         elif submitter in submitter_list:
             filtered_snps.append(snp)
             
-    print " ".join(["Found", str(len(filtered_snps)), "SNPs with >=", str(min_allele_freq),
-                    "frequency and >=", str(min_total_allele), "reported alleles!"])
+    print(" ".join(["Found", str(len(filtered_snps)), "SNPs with >=", str(min_allele_freq),
+                    "frequency and >=", str(min_total_allele), "reported alleles!"]))
     return filtered_snps
 
 
@@ -4230,7 +4230,7 @@
     for snp in snp_list:
         if snp[col] in func_list:
             filtered_snps.append(snp)
-    print "Found ", len(filtered_snps), " SNPs with functional significance"
+    print("Found ", len(filtered_snps), " SNPs with functional significance")
     return filtered_snps
             
         
@@ -4244,7 +4244,7 @@
     """ Take a file with snps or regions that must be captured by mips and a list 
     of other variations of interest (created in ucsc table format) and return a target
     dictionary"""
-    print "Extracting target snps from file " + must_file
+    print("Extracting target snps from file " + must_file)
     # create a dict of positions that should be targeted
     targets = {}
     # top priority will be given to a must have list of rs numbers 
@@ -4273,7 +4273,7 @@
         # from the coordinates, create the dict key
         key = snp_chr + ":" + snp_begin + "-" + snp_end
         # check if the key is already in the dict
-        if not key in targets.keys():
+        if not key in list(targets.keys()):
             # add snp to dictionary
             targets[key] = {"chrom":snp_chr, "begin":snp_begin, "end":snp_end,                             "name": snp_name, "diff": "na", "source": src}
     # return targets dictionary
@@ -4301,8 +4301,8 @@
     for gene in gene_list:
         if gene[1] == refseq_id:
             gene_found = 1
-            starts.extend(map(int, gene[9].split(",")[:-1]))
-            ends.extend(map(int, gene[10].split(",")[:-1]))
+            starts.extend(list(map(int, gene[9].split(",")[:-1])))
+            ends.extend(list(map(int, gene[10].split(",")[:-1])))
             gene_names.append(gene[12])
             gene_ids.append(gene[1])
             break
@@ -4350,7 +4350,7 @@
         out["ids"] = gene_ids
         return out
     else:
-        print "RefSeq id not found in gene list."
+        print("RefSeq id not found in gene list.")
         return 1
             
         
@@ -4458,27 +4458,27 @@
     uncovered_set = set()
     for r in uncovered_regions:
         try:
-            uncovered_set.update(xrange(r[0], r[1] + 1))
+            uncovered_set.update(range(r[0], r[1] + 1))
         except IndexError:
             pass
     covered_set = set()
     for r in covered_regions:
         try:
-            covered_set.update(xrange(r[0], r[1] + 1))
+            covered_set.update(range(r[0], r[1] + 1))
         except IndexError:
             pass
     uncovered_remaining = sorted(uncovered_set.difference(covered_set))
     if len(uncovered_remaining) > 0:
         uncovered = [[uncovered_remaining[i-1],
                       uncovered_remaining[i]] for i in \
-                     xrange(1, len(uncovered_remaining))\
+                     range(1, len(uncovered_remaining))\
                     if uncovered_remaining[i] - uncovered_remaining[i-1]\
                      > 1]
         unc = [uncovered_remaining[0]]
         for u in uncovered:
             unc.extend(u)
         unc.append(uncovered_remaining[-1])
-        return [[unc[i], unc[i+1]]for i in xrange(0, len(unc), 2)               if unc[i+1] - unc[i] > spacer]
+        return [[unc[i], unc[i+1]]for i in range(0, len(unc), 2)               if unc[i+1] - unc[i] > spacer]
     else:
         return []
         
@@ -4500,11 +4500,11 @@
         do_trim = False
         break_for = False
         region_list = [r for r in region_list if r != "remove"]
-        for i in xrange(len(region_list)):
+        for i in range(len(region_list)):
             if break_for:
                 break
             else:
-                for j in xrange(len(region_list)):
+                for j in range(len(region_list)):
                     if i != j:
                         reg_i = region_list[i]
                         reg_j = region_list[j]
@@ -4535,7 +4535,7 @@
                                     do_trim = True
                                     break
                                 else:
-                                    print overlap_ratio, "is outside trim range for ",                                    reg_i, reg_j
+                                    print(overlap_ratio, "is outside trim range for ",                                    reg_i, reg_j)
                     
     return region_list
                         
@@ -4560,7 +4560,7 @@
         chrom_list.append(gene[2])
     chrom_set = list(set(chrom_list))
     if len(chrom_set) == 0:
-        print "No genes found in list for exon search."
+        print("No genes found in list for exon search.")
         return {}
     while_counter = 0
     while (len(chrom_set)>1) and (while_counter < 50):
@@ -4569,16 +4569,16 @@
                 chrom_set.remove(c)
         while_counter += 1
     if len(chrom_set) > 1:
-        print ("More than one chromosomes, ",
+        print(("More than one chromosomes, ",
                chrom_set,
                ", has specified gene ", 
-               gene[12])
+               gene[12]))
         return {}
     chrom = chrom_set[0]
     for gene in gene_list:
         if gene[2] == chrom:
-            starts.extend(map(int, gene[9].split(",")[:-1]))
-            ends.extend(map(int, gene[10].split(",")[:-1]))
+            starts.extend(list(map(int, gene[9].split(",")[:-1])))
+            ends.extend(list(map(int, gene[10].split(",")[:-1])))
             gene_names.append(gene[12])
             gene_ids.append(gene[1])
             ori = gene[3]
@@ -4613,7 +4613,7 @@
         start = min(starts)
         end = max(ends)
     else:
-        print "No exons found for ",  gene_list[0][1]
+        print("No exons found for ",  gene_list[0][1])
         return {}
     # create an output dict
     out = {}
@@ -4657,8 +4657,8 @@
     # all chromosomes must be included if chromosome of the gene is not provided
     # therefore, chrom cannot be None when alternative_chr is set to 0
     if not (chrom or alternative_chr):
-        print "Chromosome of the gene %s must be specified or all chromosomes must be searched."
-        print "Specify a chromosome or set alternative chromosome to 1." %gene_name
+        print("Chromosome of the gene %s must be specified or all chromosomes must be searched.")
+        print("Specify a chromosome or set alternative chromosome to 1." %gene_name)
         return 1
     with open(refgene_file, 'r') as infile:
         coord = []
@@ -4668,7 +4668,7 @@
                 if newline[12] == gene_name:
                     coord.append(newline)
     if len(coord) < 1:
-        print "No gene found with the name ", gene_name
+        print("No gene found with the name ", gene_name)
         return []
     alter = []
     if chrom:
@@ -4704,7 +4704,7 @@
         region_list.append(query)
     regions = get_fasta_list(region_list, species)
     if multi_file:
-        for i in xrange(len(region_list)):
+        for i in range(len(region_list)):
             r = region_list[i]
             gene_name = gene_name_list[i]
             filename = wdir + gene_name + ".fa"
@@ -4734,9 +4734,9 @@
                          get_file_locations()[species]["refgene"],
                          alternative_chr=1)
     if len(gene_list) > 1:
-        print "More than one refgene entry was found for the gene ", gene_name
-        print "Exons from alternative transcripts will be merged and CDS will be generated from that."
-        print "This may lead to unreliable CDS sequence information."
+        print("More than one refgene entry was found for the gene ", gene_name)
+        print("Exons from alternative transcripts will be merged and CDS will be generated from that.")
+        print("This may lead to unreliable CDS sequence information.")
     if len(gene_list) == 0:
         return {}
     g = gene_list[0]
@@ -4746,7 +4746,7 @@
            "end": int(g[7])}
     exons = get_exons(gene_list)["exons"]
     exons_nuc = []
-    for i in xrange(len(exons)):
+    for i in range(len(exons)):
         e = exons[i]
         if not e[0] <= cds["begin"] <= e[1]:
             exons[i] == "remove"
@@ -4754,7 +4754,7 @@
             e[0] = cds["begin"]
             break
     exons = [i for i in exons if i != "remove"]
-    for i in xrange(-1, -1 * len(exons), -1):
+    for i in range(-1, -1 * len(exons), -1):
         e = exons[i]
         if not e[0] <= cds["end"] <= e[1]:
             exons[i] = "remove"
@@ -4764,7 +4764,7 @@
     exons = [i for i in exons if i != "remove"]
     sequences = []
     for e in exons:
-        exons_nuc.extend(range(e[0], e[1] + 1))
+        exons_nuc.extend(list(range(e[0], e[1] + 1)))
         sequences.append(fasta_to_sequence(
             get_fasta(cds["chrom"]
                       + ":" + str(e[0]) + "-"
@@ -4847,7 +4847,7 @@
                 targets[t]["begin"] = exons["begin"] - flank + 1
                 targets[t]["end"] = exons["end"] + flank
             except KeyError:
-                print "cannot find coordinates for ", t
+                print("cannot find coordinates for ", t)
                 targets[t]["chrom"] = "none"
                 targets[t]["begin"] = "none"
                 targets[t]["end"] = "none"
@@ -4891,7 +4891,7 @@
     # define possible capture types and check if specified type is correct
     possible_capture_types = ["exons", "targets", "whole"]
     if capture_type not in possible_capture_types:
-        print "Specified capture type %s is not available." %capture_type
+        print("Specified capture type %s is not available." %capture_type)
         return 1
     # convert region to coordinates
     coord = get_coordinates(target_region)
@@ -5065,7 +5065,7 @@
     exclude.sort(key=itemgetter(0))
     # merge snps that are close together to reduce excluded region number
     
-    for i in xrange(len(exclude)-1):
+    for i in range(len(exclude)-1):
         l_current = exclude[i]
         l_next = exclude[i+1]
         if (l_next[0] - sum(l_current)) < 18:
@@ -5108,7 +5108,7 @@
     exclude.sort(key=itemgetter(0))
     # merge snps that are close together to reduce excluded region number
     
-    for i in xrange(len(exclude)-1):
+    for i in range(len(exclude)-1):
         l_current = exclude[i]
         l_next = exclude[i+1]
         if (l_next[0] - sum(l_current)) < 18:
@@ -5276,7 +5276,7 @@
     exclude.sort(key=itemgetter(0))
     # merge snps that are close together to reduce excluded region number
     #print exclude
-    for i in xrange(len(exclude)-1):
+    for i in range(len(exclude)-1):
         l_current = exclude[i]
         l_next = exclude[i+1]
         if 0 <= l_next[0] - sum(l_current) < 18:
@@ -5505,7 +5505,7 @@
             # add NAME as a key to primer information dictionary
             primer_dic["primer_information"][primer_name]['NAME'] = primer_name
     # if some primers were eliminated from initial primer3 output, remove from dictionary
-    for primer in primer_dic["primer_information"].keys(): 
+    for primer in list(primer_dic["primer_information"].keys()): 
         if primer_dic["primer_information"][primer] == {}:
             primer_dic["primer_information"].pop(primer)
     # dump the dictionary to json file in primer3_output_DIR if outp parameter is true
@@ -5587,7 +5587,7 @@
                         try:
                             alt_tms = {}
                             ref_tm = hybrid_TM(p_temp_dir, reverse_complement(primer_seq), primer_seq, Na=Na, Mg=Mg, conc=conc)
-                            for j in xrange(-3,4):
+                            for j in range(-3,4):
                                 alt_start = para_start + j
                                 if para_primer_ori == "forward":
                                     alt_primer_key = para_chr + ":" + str(alt_start) + "-" + str(para_end)
@@ -5609,7 +5609,7 @@
                                 p_dic["ALT_BINDS"].append(p_copies[i+1])
                             else:
                                 para["ALT_BOUND"] = False
-                        except Exception, e:
+                        except Exception as e:
                             p_dic["BOWTIE_BINDS"] = [str(e)]
                     else:
                         para["ALT_TM"] = 0
@@ -5624,7 +5624,7 @@
                 para["ALT_BOUND"] = False 
             
         return [p_name, p_dic]
-    except Exception, e:
+    except Exception as e:
         p_dic["error"] = str(e)
         return [p_name, p_dic]
 
@@ -5655,7 +5655,7 @@
     tmp = primer3_output_DIR + "tmp/"
     if not os.path.exists(tmp):
         os.makedirs(tmp)
-    for primer in primers.keys():
+    for primer in list(primers.keys()):
         chore_list.append([primer, primers[primer], p_chromosomes,                          copies, tm_diff, end_identity, tmp, settings, species])
     num_process = int(settings["processors"])
     #print chore_list[-1]
@@ -5753,7 +5753,7 @@
     tmp = primer3_output_DIR + "tmp/"
     if not os.path.exists(tmp):
         os.makedirs(tmp)
-    for primer in primers.keys():
+    for primer in list(primers.keys()):
         chore_list.append([primer, primers[primer], coordinate_converter,                          copies, tm_diff, end_identity, tmp, settings, species])
     num_process = int(settings["processors"])
     p = Pool(num_process)
@@ -5817,7 +5817,7 @@
             para_end = para["BOWTIE_END"]
             para_chr = chroms[p_cop]
             alt_tms = {}
-            for i in xrange(-3,4):
+            for i in range(-3,4):
                 alt_start = para_start + i
                 if para_primer_ori == "forward":
                     alt_primer_key = para_chr + ":" + str(alt_start) + "-" + str(para_end)
@@ -5873,7 +5873,7 @@
     tmp = primer3_output_DIR + "tmp/"
     if not os.path.exists(tmp):
         os.makedirs(tmp)
-    for primer in primers.keys():
+    for primer in list(primers.keys()):
         chore_list.append([primer, primers[primer], coordinate_converter,                          copies, tm_diff, end_identity, tmp, settings, species])
     num_process = int(settings["processors"])
     #print chore_list[-1]
@@ -5908,7 +5908,7 @@
             if line.startswith(">"):
                 header = line[1:-1].split(" ")[0]
                 if header in fasta_dic:
-                    print "%s occurs multiple times in fasta file" %header
+                    print("%s occurs multiple times in fasta file" %header)
                 fasta_dic[header] = ""
                 continue
             try:
@@ -6056,7 +6056,7 @@
         try:
             revcomp.append(complement_bases[base])
         except KeyError:
-            print "Unexpected base encountered: ", base, " returned as X!!!"
+            print("Unexpected base encountered: ", base, " returned as X!!!")
             revcomp.append("X")
     return "".join(revcomp)
 
@@ -6104,7 +6104,7 @@
         try:
             values.append(str(int(c)))
         except ValueError:
-            if c in cig.keys():
+            if c in list(cig.keys()):
                 cig[c] += int("".join(values))
             else:
                 cig[c] = int("".join(values))
@@ -6166,7 +6166,7 @@
                     primers['primer_information'][primer_name]["BOWTIE_BINDS"] = []
                 if "ALT_BINDS" not in primers['primer_information'][primer_name]:
                     primers['primer_information'][primer_name]["ALT_BINDS"] = []
-            for bt_hit_name in primers['primer_information'][primer_name][bowtie_key].keys():
+            for bt_hit_name in list(primers['primer_information'][primer_name][bowtie_key].keys()):
                 bt_hit = primers['primer_information'][primer_name][bowtie_key][bt_hit_name]
                 bt_chrom = bt_hit["chrom"]
                 bt_begin = bt_hit["begin"]
@@ -6210,7 +6210,7 @@
                                 seq_list.extend([">" + primer_name, primer_seq])
                                 hit_list.extend([">alt_" + k + "_ref", reverse_complement(
                                                  primer_seq)])
-                                for j in xrange(-3,4):
+                                for j in range(-3,4):
                                     if j == 0:
                                         continue
                                     alt_start = bt_begin + j
@@ -6268,7 +6268,7 @@
                             seq_list.extend([">" + primer_name, primer_seq])
                             hit_list.extend([">alt_" + k + "_ref", reverse_complement(
                                              primer_seq)])
-                            for j in xrange(-3,4):
+                            for j in range(-3,4):
                                 if j == 0:
                                     continue
                                 alt_start = para_begin + j
@@ -6302,7 +6302,7 @@
                             para[k]["ALT_TM_DIFF"] = 100
                             para[k]["ALT_BOUND"] = False
             
-        except KeyError, e:
+        except KeyError as e:
             #print str(e)
             
             continue
@@ -6384,7 +6384,7 @@
     for primer_name in primers['primer_information']:
         try:
             primer_seq = primers['primer_information'][primer_name]["SEQUENCE"]
-            for bt_hit_name in primers['primer_information'][primer_name][bowtie_key].keys():
+            for bt_hit_name in list(primers['primer_information'][primer_name][bowtie_key].keys()):
                 bt_hit = primers['primer_information'][primer_name][bowtie_key][bt_hit_name]
                 bt_chrom = bt_hit["chrom"]
                 bt_begin = bt_hit["begin"]
@@ -6421,7 +6421,7 @@
                                 seq_list.extend([">" + primer_name, primer_seq])
                                 hit_list.extend([">alt_" + k + "_ref", reverse_complement(
                                                  primer_seq)])
-                                for j in xrange(7):
+                                for j in range(7):
                                     alt_start = bt_begin + j
                                     alt_primer_seq = bt_hit["sequence"][j:]
                                     al[j] = {}
@@ -6460,8 +6460,8 @@
                     hit_list.extend([">bt_" + bt_hit_name, reverse_complement(bt_seq)])
                     #print bt_seq
                 
-        except KeyError, e:
-            print str(e)
+        except KeyError as e:
+            print(str(e))
             
             continue
     #infile.close()
@@ -6489,7 +6489,7 @@
                     else:
                         primers["primer_information"][p_name]["PARALOG_COORDINATES"][copyname]                                       ["ALTERNATIVES"][int(h_name)]["ALT_TM"] = h_tm
                 except KeyError:
-                    print p_name, h_name, items
+                    print(p_name, h_name, items)
                     
             else:
                 bowtie_dic = primers["primer_information"][p_name][bowtie_key]
@@ -6600,7 +6600,7 @@
                 except KeyError:
                      primers["primer_information"][primer_name][bowtie_key] = {str(counter_dic[primer_name]):                          {"chrom":chrom, "begin": bt_start, "end":bt_end, "key":hit_region_key,
                           "strand":hit_str}}
-        except KeyError, ke:
+        except KeyError as ke:
             # in earlier versions of this function the primers with
             # excessive hits were removed during iteration and that lead
             # to keyerrors. Now there should be no key error
@@ -6610,7 +6610,7 @@
     # get the fasta sequences of all hits
     sequence_dic = get_fasta_list(keys, species)
     # remove primers with too many hits
-    for p in primers["primer_information"].keys():
+    for p in list(primers["primer_information"].keys()):
         if "remove" in primers["primer_information"][p]:
             primers["primer_information"].pop(p)
         else:
@@ -6664,17 +6664,17 @@
                         primer["ALT_BINDS"].append(c)
                         para[c].update(alts[sorted_alts[0]])
                     para[c].pop("ALTERNATIVES")
-                except KeyError, e:
+                except KeyError as e:
                     try:
                         para[c].pop("ALTERNATIVES")
-                    except KeyError, e:
+                    except KeyError as e:
                         pass
                 except IndexError:
                     try:
                         para[c].pop("ALTERNATIVES")
-                    except KeyError, e:
+                    except KeyError as e:
                         pass
-    except KeyError, e:
+    except KeyError as e:
         pass
     if outp:
         with open(primer3_output_DIR + output_file, "w") as outfile:
@@ -6705,7 +6705,7 @@
     # default is a primer file
     mip = 0
     # change mip to 1 if mips are analyzed
-    if "pair_information" in primers.keys():
+    if "pair_information" in list(primers.keys()):
         mip = 1
     counter = 0
     # read bowtie hits
@@ -6733,7 +6733,7 @@
                 intended = 0
                 # get sequence of mip (if mip) from primer dic
                 if mip:
-                    if "pairs" in primers["pair_information"][primer_name].keys():
+                    if "pairs" in list(primers["pair_information"][primer_name].keys()):
                         para = primers["pair_information"][primer_name]["pairs"]
                         for p in para:
                             mip_start = para[p]["mip_start"] -10
@@ -6743,7 +6743,7 @@
                                 intended = 1
                 # get sequence of primer from dic
                 else:
-                    if "PARALOG_COORDINATES" in primers['primer_information'][primer_name].keys():
+                    if "PARALOG_COORDINATES" in list(primers['primer_information'][primer_name].keys()):
                         para = primers['primer_information'][primer_name]["PARALOG_COORDINATES"]
                         # para is a dic like {C0:{"CHR": "chr4", "GENOMIC_START" ..}, C1:{..
                         for k in para:
@@ -6789,10 +6789,10 @@
                 if temp[primer_name] < int(N):
                     outfile.write(line)
                 if temp[primer_name] > int(M):
-                    if "pair_information" in primers.keys():
-                        if primer_name in primers["pair_information"].keys():
+                    if "pair_information" in list(primers.keys()):
+                        if primer_name in list(primers["pair_information"].keys()):
                             primers["pair_information"].pop(primer_name)
-                    elif primer_name in primers["primer_information"].keys():
+                    elif primer_name in list(primers["primer_information"].keys()):
                         primers["primer_information"].pop(primer_name)
         except KeyError:
             continue
@@ -6826,7 +6826,7 @@
     # default is a primer file
     mip = 0
     # change mip to 1 if mips are analyzed
-    if "pair_information" in primers.keys():
+    if "pair_information" in list(primers.keys()):
         mip = 1
     # read bowtie hits
     for line in infile:
@@ -6910,7 +6910,7 @@
     with open(primer3_output_DIR + primer_file, "r") as handle:
         primers = json.load(handle)
     # are we adding bowtie information for mips or primers?
-    if "pair_information" in primers.keys():
+    if "pair_information" in list(primers.keys()):
         # then primers already paired and we are looking at MIP data
         mip = 1
     else:
@@ -7003,12 +7003,12 @@
             # all bowtie dictionaries for a single mip/primer are appended
             # to a list
             if mip:
-                if bowtie_key in primers['pair_information']                   [primer_name]['mip_information'].keys():
+                if bowtie_key in list(primers['pair_information']                   [primer_name]['mip_information'].keys()):
                     primers['pair_information'][primer_name]                    ['mip_information'][bowtie_key].append(temp_dic)
                 else:
                     primers['pair_information'][primer_name]                    ['mip_information'][bowtie_key] = [temp_dic]
             else:
-                if bowtie_key in primers['primer_information'][primer_name].keys():
+                if bowtie_key in list(primers['primer_information'][primer_name].keys()):
                     primers['primer_information'][primer_name][bowtie_key].append(temp_dic)
                 else:
                     primers['primer_information'][primer_name][bowtie_key] = [temp_dic]
@@ -7050,7 +7050,7 @@
     primers = primer_file
     #print TM, hit_threshold, lower_tm, lower_hit_threshold, species
     #print str(len(primers["primer_information"])) + " primers analyzed!"
-    for primer in primers["primer_information"].keys():
+    for primer in list(primers["primer_information"].keys()):
         # create a hit count parameter for hits with significant tm
         hc = 0
         lhc = 0
@@ -7075,9 +7075,9 @@
                 except KeyError:
                     continue
             
-            if primer in primers["primer_information"].keys():
+            if primer in list(primers["primer_information"].keys()):
                 primers["primer_information"][primer].pop("bowtie_information_" + species)
-        except KeyError, ke:
+        except KeyError as ke:
             #print ke
             continue
     if outp:       
@@ -7106,16 +7106,16 @@
     primers = json.load(infile)
     infile.close()
     # check if it is a mip dictionary or primer dictionary
-    if "pair_information" in primers.keys():
+    if "pair_information" in list(primers.keys()):
         # report how many primer pairs are analyzed
         #print str(len(primers["pair_information"])) + " mips analyzed!"
         # remove bowtie hits with TMs higher than given TM
-        for primer in primers["pair_information"].keys():
+        for primer in list(primers["pair_information"].keys()):
             # create a hit count parameter for hits with significant tm
             hc = 0
             lhc = 0
             # check if bowtie_information key exists for given species
-            if ("bowtie_information_" + species) in primers["pair_information"]               [primer]["mip_information"].keys():
+            if ("bowtie_information_" + species) in list(primers["pair_information"]               [primer]["mip_information"].keys()):
                 # extract bowtie information
                 bowtie = primers["pair_information"][primer]["mip_information"]                         ["bowtie_information_" + species]
                 for hit in bowtie:
@@ -7125,30 +7125,30 @@
                     # Therefore, we have to check if it is a string or not first.
                     try:
                         # if TM not a list, TypeError is raised
-                        if ("TM" in hit.keys()) and (hit["TM"][0] >= TM)                            and (primer in primers["pair_information"].keys()):
+                        if ("TM" in list(hit.keys())) and (hit["TM"][0] >= TM)                            and (primer in list(primers["pair_information"].keys())):
                             hc += 1
                             if hc > hit_threshold:
                                 primers["pair_information"].pop(primer)
                                 break
-                        elif ("TM" in hit.keys()) and (hit["TM"][0] >= lower_tm)                            and (primer in primers["pair_information"].keys()):
+                        elif ("TM" in list(hit.keys())) and (hit["TM"][0] >= lower_tm)                            and (primer in list(primers["pair_information"].keys())):
                             lhc += 1
                             if lhc > lower_hit_threshold:
                                 primers["pair_information"].pop(primer)
                                 break
                     except TypeError:
-                        if ("TM" in hit.keys()) and (hit["TM"] >= TM)                            and (primer in primers["pair_information"].keys()):
+                        if ("TM" in list(hit.keys())) and (hit["TM"] >= TM)                            and (primer in list(primers["pair_information"].keys())):
                             hc += 1
                             if hc > hit_threshold:
                                 primers["pair_information"].pop(primer)
                                 break
-                        elif ("TM" in hit.keys()) and (hit["TM"] >= lower_tm)                            and (primer in primers["pair_information"].keys()):
+                        elif ("TM" in list(hit.keys())) and (hit["TM"] >= lower_tm)                            and (primer in list(primers["pair_information"].keys())):
                             lhc += 1
                             if lhc > lower_hit_threshold:
                                 primers["pair_information"].pop(primer)
                                 break
                 # if a primer is still in dictionary after filtering for bowtie hits
                 # keep the primer and remove the bowtie hits
-                if primer in primers["pair_information"].keys():
+                if primer in list(primers["pair_information"].keys()):
                     primers["pair_information"][primer]                           ["mip_information"].pop("bowtie_information_" + species)
 
         # report how many mips are left after filtering
@@ -7157,42 +7157,42 @@
     # if dictionary is for primers only:
     else:
         #print str(len(primers["primer_information"])) + " primers analyzed!"
-        for primer in primers["primer_information"].keys():
+        for primer in list(primers["primer_information"].keys()):
             # create a hit count parameter for hits with significant tm
             hc = 0
             lhc = 0
             # check if bowtie information exists in dic
-            if ("bowtie_information_" + species) in                primers["primer_information"][primer].keys():
+            if ("bowtie_information_" + species) in                list(primers["primer_information"][primer].keys()):
                 # get bowtie information for the primer
                 bowtie = primers["primer_information"][primer]                         ["bowtie_information_" + species]
                 for hit in bowtie:
                     # check if TM information is included in bowtie
                     # for the same TypeError as the mips above
                     try:
-                        if ("TM" in hit.keys()) and (float(hit["TM"][0]) >= TM)                            and (primer in primers["primer_information"].keys()):
+                        if ("TM" in list(hit.keys())) and (float(hit["TM"][0]) >= TM)                            and (primer in list(primers["primer_information"].keys())):
                             hc += 1
                             if hc > hit_threshold:
                                 primers["primer_information"].pop(primer)
                                 break
-                        elif ("TM" in hit.keys()) and (float(hit["TM"][0]) >= lower_tm)                            and (primer in primers["primer_information"].keys()):
+                        elif ("TM" in list(hit.keys())) and (float(hit["TM"][0]) >= lower_tm)                            and (primer in list(primers["primer_information"].keys())):
                             lhc += 1
                             if lhc > lower_hit_threshold:
                                 primers["primer_information"].pop(primer)
                                 break
                         
                     except TypeError:
-                        if ("TM" in hit.keys()) and (float(hit["TM"]) >= TM)                            and (primer in primers["primer_information"].keys()):
+                        if ("TM" in list(hit.keys())) and (float(hit["TM"]) >= TM)                            and (primer in list(primers["primer_information"].keys())):
                             hc += 1
                             if hc > hit_threshold:
                                 primers["primer_information"].pop(primer)
                                 break
-                        elif ("TM" in hit.keys()) and (float(hit["TM"]) >= lower_tm)                            and (primer in primers["primer_information"].keys()):
+                        elif ("TM" in list(hit.keys())) and (float(hit["TM"]) >= lower_tm)                            and (primer in list(primers["primer_information"].keys())):
                             lhc += 1
                             if lhc > lower_hit_threshold:
                                 primers["primer_information"].pop(primer)
                                 break
                 
-                if primer in primers["primer_information"].keys():
+                if primer in list(primers["primer_information"].keys()):
                     primers["primer_information"][primer].pop("bowtie_information_" + species)
                 
         #print str(len(primers["primer_information"])) + " primers with mispriming TM < " + str(TM)
@@ -7222,13 +7222,13 @@
     primers = json.load(infile)
     infile.close()
     # check if it is a mip dictionary or primer dictionary
-    if "pair_information" in primers.keys():
+    if "pair_information" in list(primers.keys()):
         # report how many primer pairs are analyzed
         #print str(len(primers["pair_information"])) + " mips analyzed!"
         # remove bowtie hits with TMs higher than given TM
-        for primer in primers["pair_information"].keys():
+        for primer in list(primers["pair_information"].keys()):
             # check if bowtie_information key exists for given species
-            if ("bowtie_information_" + species) in primers["pair_information"]               [primer]["mip_information"].keys():
+            if ("bowtie_information_" + species) in list(primers["pair_information"]               [primer]["mip_information"].keys()):
                 # extract bowtie information
                 bowtie = primers["pair_information"][primer]["mip_information"]                         ["bowtie_information_" + species]
                 for hit in bowtie:
@@ -7237,18 +7237,18 @@
                     # information to the dictionary, TM can be a list or a string
                     # Therefore, we have to check if it is a string or not first.
                     try:
-                        if ("TM" in hit.keys()) and (float(hit["TM"]) >= TM)                            and (primer in primers["pair_information"].keys()):
+                        if ("TM" in list(hit.keys())) and (float(hit["TM"]) >= TM)                            and (primer in list(primers["pair_information"].keys())):
                             # remove primers with TM higher than specified
                             primers["pair_information"].pop(primer)
                             break
                     except TypeError:
                         # if TM is a list and not a string, TypeError is raised
-                        if ("TM" in hit.keys()) and (float(hit["TM"][0]) >= TM)                            and (primer in primers["pair_information"].keys()):
+                        if ("TM" in list(hit.keys())) and (float(hit["TM"][0]) >= TM)                            and (primer in list(primers["pair_information"].keys())):
                             primers["pair_information"].pop(primer)
                             break
                 # if a primer is still in dictionary after filtering for bowtie hits
                 # keep the primer and remove the bowtie hits
-                if primer in primers["pair_information"].keys():
+                if primer in list(primers["pair_information"].keys()):
                     primers["pair_information"][primer]                           ["mip_information"].pop("bowtie_information_" + species)
         # report how many mips are left after filtering
         #print str(len(primers["pair_information"])) +\
@@ -7256,9 +7256,9 @@
     # if dictionary is for primers only:
     else:
         #print str(len(primers["primer_information"])) + " primers analyzed!"
-        for primer in primers["primer_information"].keys():
+        for primer in list(primers["primer_information"].keys()):
             # check if bowtie information exists in dic
-            if ("bowtie_information_" + species) in                primers["primer_information"][primer].keys():
+            if ("bowtie_information_" + species) in                list(primers["primer_information"][primer].keys()):
                 # get bowtie information for the primer
                 bowtie = primers["primer_information"][primer]                         ["bowtie_information_" + species]
                 for hit in bowtie:
@@ -7266,14 +7266,14 @@
                     # for the same TypeError as the mips abova
                     # use try/except statements
                     try:
-                        if ("TM" in hit.keys()) and (float(hit["TM"]) >= TM)                            and (primer in primers["primer_information"].keys()):
+                        if ("TM" in list(hit.keys())) and (float(hit["TM"]) >= TM)                            and (primer in list(primers["primer_information"].keys())):
                             primers["primer_information"].pop(primer)
                             break
                     except TypeError:
-                        if ("TM" in hit.keys()) and (float(hit["TM"][0]) >= TM)                            and (primer in primers["primer_information"].keys()):
+                        if ("TM" in list(hit.keys())) and (float(hit["TM"][0]) >= TM)                            and (primer in list(primers["primer_information"].keys())):
                             primers["primer_information"].pop(primer)
                             break
-                if primer in primers["primer_information"].keys():
+                if primer in list(primers["primer_information"].keys()):
                     primers["primer_information"][primer].pop("bowtie_information_" + species)
         #print str(len(primers["primer_information"])) + " primers with mispriming TM < " + str(TM)
     # write dictionary to file in primer3_output_DIR
@@ -7316,10 +7316,10 @@
     lig = ligation["primer_information"]
     # check if extension and ligation dictionaries have primers
     if len(ext) == 0:
-        print "There are no extension primers."
+        print("There are no extension primers.")
         return 1
     if len(lig) == 0:
-        print "There are no ligation primers."
+        print("There are no ligation primers.")
         return 1
     # assign sequence information dict to shorter name
     ext_seq = extension["sequence_information"]
@@ -7336,7 +7336,7 @@
     primer_pairs["sequence_information"]['SEQUENCE_TARGET'] =     extension["sequence_information"]['SEQUENCE_TARGET']
     primer_pairs["sequence_information"]['SEQUENCE_ID'] =     extension["sequence_information"]['SEQUENCE_ID']
     # pick primer pairs 
-    for e in ext.keys():
+    for e in list(ext.keys()):
         # extension primer information for this mip will be e_info
         e_info = ext[e]
         # get primer coordinates
@@ -7351,7 +7351,7 @@
         e_binds = e_info["BOWTIE_BINDS"]
         e_alt_binds = e_info["ALT_BINDS"]
         # find a ligation primer
-        for l in lig.keys():
+        for l in list(lig.keys()):
             l_info = lig[l]
             # get primer coordinates
             lig_start = l_info["GENOMIC_START"]
@@ -7417,7 +7417,7 @@
                     # check if any pairs' product is within size limits
                     pair_found = 0
                     captured_copies = []
-                    for p in pairs.keys():
+                    for p in list(pairs.keys()):
                         max_insertion_size = region_insertions.loc[
                             (region_insertions["copy_chrom"]
                              == pairs[p]["chrom"])
@@ -7440,7 +7440,7 @@
                     if pair_found:
                         # if a pair is found for any copy
                         # remove minimum size restriction for other copies
-                        for p in pairs.keys():
+                        for p in list(pairs.keys()):
                             if p in captured_copies:
                                 continue
                             max_insertion_size = region_insertions.loc[
@@ -7519,7 +7519,7 @@
                                 continue
                         # check if any pairs' product is within size limits
                         captured_copies = []
-                        for a in alts.keys():
+                        for a in list(alts.keys()):
                             # does it satisfy arm setting?
                             good_alt = 0
                             if alternative_arms == "any":
@@ -7543,7 +7543,7 @@
                         primer_pairs["pair_information"][pair_name]["alt_copies"] = captured_copies
     # return if no pairs found
     if len(primer_pairs["pair_information"]) == 0:
-        print "No primer pairs found."
+        print("No primer pairs found.")
         return 1
     # print how many primer pairs are found
     #print str(len(primer_pairs["pair_information"])) + " primer pairs found!"
@@ -7613,7 +7613,7 @@
     pairs = primer_pairs
     # check if the primer dictionary is empty
     if len(pairs["pair_information"]) == 0:
-        print "There are no primer pairs in dictionary"
+        print("There are no primer pairs in dictionary")
         return 1
     # use standard backbone if none is specified
     if backbone == None:
@@ -7632,7 +7632,7 @@
                                                 [primers]["captured_copies"])}}
         # add it to the pair dictionary
         
-        if "alt_copies" in pairs["pair_information"][primers].keys():
+        if "alt_copies" in list(pairs["pair_information"][primers].keys()):
             alt_sequences = {}
             alt_counter = 0
             alt = pairs["pair_information"][primers]["alt_copies"]
@@ -7645,7 +7645,7 @@
                 if "ligation" in p_para[a]["alternative_arms"]:
                     ligation_sequence = l_para[a]["ALT_SEQUENCE"].upper()
                 value_found = 0
-                for key,value in alt_sequences.iteritems():
+                for key,value in alt_sequences.items():
                     if [extension_sequence, ligation_sequence] == value["sequences"]:
                         value_found = 1
                         value["copies"].append(a)
@@ -7727,7 +7727,7 @@
             dS = float(newline [3][-10:])
             TM = float(newline [4][-8:])
             # if this is the first hairpin information for this mip, add the hairpin information
-            if not "HAIRPIN" in hairpin_dic["pair_information"][line]["mip_information"]["ref"].keys():
+            if not "HAIRPIN" in list(hairpin_dic["pair_information"][line]["mip_information"]["ref"].keys()):
                 hairpin_dic["pair_information"][line]["mip_information"]["ref"]["HAIRPIN"]                = {'dG':dG, 'dH':dH, 'dS':dS, 'TM':TM}
             # if there was already another hairpin for this mip, replace it with this new hairpin
             # if it has a dG vaule that is smaller than the previous mip. 
@@ -7736,15 +7736,15 @@
     # print starting number of mips
     #print str(len(hairpin_dic["pair_information"])) + " mips analyzed!"
